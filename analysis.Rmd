---
title: "IVA2019 Analysis"
author: "CSaund"
date: "2/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
```

AA = "available audience"
E = entity
U = unpolite
O = original
AAOP = AA open
AAS = AA Small
ES = E separate
EC = E control
UT = U together
UF = U force

## Load 'N' Wrangle

Load these bad larrys
Annoyingly can't create dynamically named variables in R AFAIK, so manual
```{r}
condition_names <- c('aao', 'aas', 'aaop', 'eo','ec','es','uo','uf','ut')
aao <- read.csv('AAO_copy.csv')
aas <- read.csv('AAS_copy.csv')
aaop <- read.csv('AAOP_copy.csv')
eo <- read.csv('EO_copy.csv')
ec <- read.csv('EC_copy.csv')
es <- read.csv('ES_copy.csv')
uo <- read.csv('UO_copy.csv')
ut <- read.csv('UT_copy.csv')
uf <- read.csv('UF_copy.csv')
```

First step, collapse responses into metaphor-y responses. 
1. (Force is conflict) Combine rows for "There is tension between people in the group" and "People in the group disagree with one another"
2. (Physical closeness is ideological closeness) Combine "People in this group generally get along" and "People in the group are working together to solve a problem"
3. (Abstract ideas have concrete properties (size)) "She is referring to everybody in the group" and "This group consists of many people"
4. (Open is accessible) "The speaker likes the people in the group" and "The speaker is open to feedback from the group"
5. (Being in control is being above) "The speaker is annoyed with the group" and "The speaker is in control of the group"

We add a "group"column that actually tells us what the metaphors were in reference to. 
```{r}
group_by_metaphor <- function(data) {
  data$group <- ""
  for(row in 1:nrow(data)) {
    if (data$Answer.Choices[row] == "People in the group are working together to solve a problem" || 
        data$Answer.Choices[row] == "People in the group generally get along") {
      data$group[row] <- "closeness"
    } else if (data$Answer.Choices[row] == "There is tension between people in the group" || 
               data$Answer.Choices[row] == "People in the group disagree with one another") {
      data$group[row] <- "conflict"
    } else if (data$Answer.Choices[row] == "She is referring to everybody in the group" || 
               data$Answer.Choices[row] == "This group consists of many people") {
      data$group[row] <- "size"
    } else if (data$Answer.Choices[row] == "The speaker likes the people in the group" || 
               data$Answer.Choices[row] == "The speaker is open to feedback from the group") {
      data$group[row] <- "open"
    } else if (data$Answer.Choices[row] == "The speaker is in annoyed with the group" || 
               data$Answer.Choices[row] == "The speaker is in control of the group") {
      data$group[row] <- "control"
    } else {
      # for some reason it's not recognizing the annoyed case, so let's throw it in the else
      # cause that seems safe.
      data$group[row] <- "control"
    }
  }
  return(data)
}
```

This means we're gonna have to calculate our own scores
```{r}
# Get all the overall scores (mean for condition) for a dataset
get_scores <- function(data) {
  scores <- c()
  for(row in 1:nrow(data)) {
    total_score = 0
    for(col in 2:11) {
      total_score = total_score + data[row,col] * (12 - col)
    }
    scores[row] <- (total_score / data[row,12])
  }
  return(scores)
}

# actually add the scores to the dataframe
append_scores <- function(data) {
  scores <- get_scores(data)
  data$normalized_score=scores
  return(data)
}

# Aggregate the data for columns that have the 
# same metaphor measure
bucket_by_group <- function(data) {
  return (aggregate(list(X1=data$X1, 
                 X2=data$X2,
                 X3=data$X3,
                 X4=data$X4,
                 X5=data$X5,
                 X6=data$X6,
                 X7=data$X7,
                 X8=data$X8,
                 X9=data$X9,
                 X10=data$X10,
                 Total=data$Total), 
             by=list(metaphor_measure=data$group), 
             FUN=sum))
}
```
Sweet, now instead of dealing with survey statements we're dealing with semantic meaning. 

Just to be clear, this is what we're doing start to finish to get a nice and shiny 
bucketed dataset with new scores we can then compare based on the semantic
meanings and not the actual survey statements.
So let's transform all our old data so it's nice and bucketed, and sorted by score
```{r}
transform_data <- function(data) {
  transformed_data <- data %>%
    group_by_metaphor() %>%
    bucket_by_group() %>%
    append_scores()
  return(transformed_data[rev(order(transformed_data$normalized_score)),])
}

aao <- transform_data(aao)
aas <- transform_data(aas)
aaop <- transform_data(aaop)

eo <- transform_data(eo)
ec <- transform_data(ec)
es <- transform_data(es)

uo <- transform_data(uo)
uf <- transform_data(uf)
ut <- transform_data(ut)
```


Let's do ourselves a favor and put these next to each other, so we have one table per
gesture, as opposed to 3. There is *for sure* a nicer way to do this but this is quick and dirty.
I'm sorry for what I've done.
```{r}
summarise_gesture <- function(orig, manip1, manip1_name, manip2, manip2_name) {
  # drop columns we don't care about
  keep = c("metaphor_measure", "normalized_score")
  
  orig <- orig[keep] 
  colnames(orig)[2] <- "original"
  
  manip1 <- manip1[keep]
  colnames(manip1)[2] <- manip1_name
  
  manip2 <- manip2[keep]
  colnames(manip2)[2] <- manip2_name
  
  summary_table <- left_join(orig, manip1, by="metaphor_measure") %>%
    left_join(manip2, by="metaphor_measure")
}

aa_summary <- summarise_gesture(aao, 
                                aas, "small",
                                aaop, "open")
                                
entity_summary <- summarise_gesture(eo, 
                                es, "separate",
                                ec, "chest")
                                
unpolite_summary <- summarise_gesture(uo, 
                                ut, "together",
                                uf, "force")
```


Now we have nice summaries of the data, but let's make sure we have a big table too.
```{r}
scale_scores <- function(data) {
  data$X1 <- data$X1 * 10
  data$X2 <- data$X2 * 9
  data$X3 <- data$X3 * 8
  data$X4 <- data$X4 * 7
  data$X5 <- data$X5 * 6
  data$X6 <- data$X6 * 5
  data$X7 <- data$X7 * 4
  data$X8 <- data$X8 * 3
  data$X9 <- data$X9 * 2
  data$X10 <- data$X10 * 1
  return(data)
}

scale_gather_normalize <- function(data) {
  data <- scale_scores(data) %>%
    gather("ranking_position", "scaled_score", 2:11)
  data$normalized_scores <- data$scaled_score / data$Total
  return(data)
}

scale_and_normalize <- function(orig_data, cond1_data, cond1_name, cond2_data, cond2_name) {
  # scale all the scores
  orig_data <- scale_gather_normalize(orig_data) 
  cond1_data <- scale_gather_normalize(cond1_data) 
  cond2_data <- scale_gather_normalize(cond2_data) 
  
  # name it up nice
  orig_data$condition <- "original"
  cond1_data$condition <- cond1_name
  cond2_data$condition <- cond2_name
  
  #concat the datasets
  return(rbind(orig_data, cond1_data, cond2_data))
}

 total_unpolite <- scale_and_normalize(uo, ut, "together", uf, "forced")
 total_entity <- scale_and_normalize(eo, ec, "chest", es, "separated")
 total_audience <- scale_and_normalize(aao, aas, "small", aaop, "open")
```

## Plot 'Em and Load 'Em

Our "outliers" are actually the most important part of our data, so let's make sure we visualize them as such:
```{r}
# define the summary function to describe our stats the way we want
f <- function(x) {
  r <- quantile(x, probs = c(0.25, 0.5, 0.75, 0.999, 0.99999))
  names(r) <- c("ymin", "lower", "middle", "upper", "ymax")
  r
}

```

And now let's graph if up real style 
```{r}
plot_the_thing <- function(data) {
  data_plot <- ggplot(data, aes(x=metaphor_measure, y=normalized_scores, fill=condition)) + 
  stat_summary(fun.data=f, geom="boxplot", position="dodge2") + 
  facet_wrap(~metaphor_measure, scale="free")
  
  return(data_plot)
}

unpolite_plot <- plot_the_thing(total_unpolite)
audience_plot <- plot_the_thing(total_audience)
entity_plot <- plot_the_thing(total_entity)
```
Unpolite Plot:
```{r}
unpolite_plot
```
Audience Plot:
```{r}
audience_plot
```
Entity Plot
```{r}
entity_plot
```

Great, that gives a better picture of everything together


## Stats on Stats on Stats
```{r}
transpose_df <- function(data, transpose_var="metaphor_measure") {
  n <- data$transpose_var
  data <- as.data.frame(t(data[,-1]))
  colnames(data) <- n
  data$transpose_var <- factor(row.names(data))
  return(data)
}
```

Let's check to see, for example, how much the variation in 'closeness' is dependent on our condition
```{r}
unpolite_closeness_aov <- aov(normalized_scores ~ condition, data=filter(total_unpolite, metaphor_measure=='closeness'))
summary(unpolite_closeness_aov)
```

Basically the answer is... not much. But we can try for all of the different conditions.
```{r}
generate_anovas <- function(data) {
  print('closeness, conflict, control, open, size')
  print(summary(generate_anova(data, 'closeness')))
  print(summary(generate_anova(data, 'conflict')))
  print(summary(generate_anova(data, 'control')))
  print(summary(generate_anova(data,'open')))
  print(summary(generate_anova(data,'size')))
}

# not particularly useful up above, but handy for having during test period. 
generate_anova <- function(data, metaphor_filter) {
  return(aov(normalized_scores ~ condition, data=filter(data, metaphor_measure==metaphor_filter)))
}
```

```{r}
print('unpolite')
generate_anovas(total_unpolite)
```

```{r}
print('audience')
generate_anovas(total_audience)
```

```{r}
print('entity')
generate_anovas(total_entity)
```


###TODO: MANOVAS // compare between groups??


### Bootstrapping the ~Data~
Now let's try bootstrapping this bad boy
```{r}
generate_bootstrapped_data <- function(data, n) {
  generated_data <- data[0,]
  for(i in 1:n) {
    generated_data <- rbind(generated_data, sample_n(data, 1))
  }
  return(generated_data)
}
```


Perhaps fortunately, perhaps not, this brings significance values wayyyyy up. Let's compare:
```{r}
unpolite_bootstrapped <- generate_bootstrapped_data(total_unpolite, 600)
print('unpolite')
generate_anovas(unpolite_bootstrapped)
```

```{r}
audience_bootstrapped <- generate_bootstrapped_data(total_audience, 600)
print('audience')
generate_anovas(audience_bootstrapped)
```

```{r}
entity_bootstrapped <- generate_bootstrapped_data(total_entity, 600)
print('entity')
generate_anovas(entity_bootstrapped)
```


Now we have to prove that our bootstrapped dataset isn't garbaggio from our first one:
```{r}

```


### Show Me What Matters
Fine, I will. 

# "Unpolite"
```{r}
print_anova_significance <- function(data) {
  print('closeness')
  print(summary(generate_anova(data, 'closeness'))[[1]][["Pr(>F)"]][1])
  print('conflict')
  print(summary(generate_anova(data, 'conflict'))[[1]][["Pr(>F)"]][1])
  print('control')
  print(summary(generate_anova(data, 'control'))[[1]][["Pr(>F)"]][1])
  print('open')
  print(summary(generate_anova(data,'open'))[[1]][["Pr(>F)"]][1])
  print('size')
  print(summary(generate_anova(data,'size'))[[1]][["Pr(>F)"]][1])
}

print_anova_significance(unpolite_bootstrapped)
```


# "Available Audience"
```{r}
print_anova_significance(audience_bootstrapped)
```

# "Entity"
```{r}
print_anova_significance(entity_bootstrapped)
```

