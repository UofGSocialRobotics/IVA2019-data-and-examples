---
title: "IVA2019 Analysis"
author: "--"
date: "2/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(pwr)
library(ordinal)
```

AA = "available audience"
E = entity
U = unpolite
O = original
AAOP = AA open
AAS = AA Small
ES = E separate
EC = E control
UT = U together
UF = U force

## Load 'N' Wrangle

Load these bad larrys
Annoyingly can't create dynamically named variables in R AFAIK, so manual
```{r}
condition_names <- c('aao', 'aas', 'aaop', 'eo','ec','es','uo','uf','ut')
aao <- read.csv('aao_2.csv')
aas <- read.csv('aas_2.csv')
aaop <- read.csv('aaop_2.csv')
eo <- read.csv('eo_2.csv')
ec <- read.csv('ec_2.csv')
es <- read.csv('es_2.csv')
uo <- read.csv('uo_2.csv')
ut <- read.csv('ut_2.csv')
uf <- read.csv('uf_2.csv')
```

First step, collapse responses into metaphor-y responses. 
1. (Force is conflict) Combine rows for "There is tension between people in the group" and "People in the group disagree with one another"
2. (Physical closeness is ideological closeness) Combine "People in this group generally get along" and "People in the group are working together to solve a problem"
3. (Abstract ideas have concrete properties (size)) "She is referring to everybody in the group" and "This group consists of many people"
4. (Open is accessible) "The speaker likes the people in the group" and "The speaker is open to feedback from the group"
5. (Being in control is being above) "The speaker is annoyed with the group" and "The speaker is in control of the group"

We add a "group"column that actually tells us what the metaphors were in reference to. 
```{r}
group_by_metaphor <- function(data) {
  data$metaphor_measure <- ""
  for(row in 1:nrow(data)) {
    if (data$Answer.Choices[row] == "People in the group are working together to solve a problem" || 
        data$Answer.Choices[row] == "People in the group generally get along") {
      data$metaphor_measure[row] <- "closeness"
    } else if (data$Answer.Choices[row] == "There is tension between people in the group" || 
               data$Answer.Choices[row] == "People in the group disagree with one another") {
      data$metaphor_measure[row] <- "conflict"
    } else if (data$Answer.Choices[row] == "She is referring to everybody in the group" || 
               data$Answer.Choices[row] == "This group consists of many people") {
      data$metaphor_measure[row] <- "size"
    } else if (data$Answer.Choices[row] == "The speaker likes the people in the group" || 
               data$Answer.Choices[row] == "The speaker is open to feedback from the group") {
      data$metaphor_measure[row] <- "open"
    } else if (data$Answer.Choices[row] == "The speaker is in annoyed with the group" || 
               data$Answer.Choices[row] == "The speaker is in control of the group") {
      data$metaphor_measure[row] <- "control"
    } else {
      # for some reason it's not recognizing the annoyed case, so let's throw it in the else
      # cause that seems safe.
      data$metaphor_measure[row] <- "control"
    }
  }
  return(data)
}

group_by_statement <- function(data) {
  data$metaphor_measure <- ""
  for(row in 1:nrow(data)) {
    if (data$Answer.Choices[row] == "People in the group are working together to solve a problem") {
               data$metaphor_measure[row] <- "WorkTogether"
    } else if (data$Answer.Choices[row] == "There is tension between people in the group") {
              data$metaphor_measure[row] <- "Tension"
    } else if (data$Answer.Choices[row] == "She is referring to everybody in the group") {
              data$metaphor_measure[row] <- "Everybody"
    } else if (data$Answer.Choices[row] == "The speaker likes the people in the group") {
              data$metaphor_measure[row] <- "Likes"
    } else if (data$Answer.Choices[row] == "The speaker is in annoyed with the group") {
              data$metaphor_measure[row] <- "Annoyed"
    } else if (data$Answer.Choices[row] == "People in the group generally get along") {
              data$metaphor_measure[row] <- "GetAlong"
    } else if (data$Answer.Choices[row] == "People in the group disagree with one another") {
               data$metaphor_measure[row] <- "Disagree"
    } else if (data$Answer.Choices[row] == "This group consists of many people") {
              data$metaphor_measure[row] <- "ManyPeople"
    } else if (data$Answer.Choices[row] == "The speaker is open to feedback from the group") {
      data$metaphor_measure[row] <- "Feedback"
    } else if (data$Answer.Choices[row] == "The speaker is in control of the group") {
              data$metaphor_measure[row] <- "Control"
    } else {
      # for some reason it's not recognizing the annoyed case, so let's throw it in the else
      # cause that seems safe.
      data$metaphor_measure[row] <- "Annoyed"
    }
  }
  return(data)
}
```

This means we're gonna have to calculate our own scores
```{r}
# Get all the overall scores (mean for condition) for a dataset
get_scores <- function(data) {
  scores <- c()
  for(row in 1:nrow(data)) {
    total_score = 0
    for(col in 2:11) {
      total_score = total_score + data[row,col] * (12 - col)
    }
    scores[row] <- (total_score / data[row,12])
  }
  return(scores)
}

# variances while we're at it too
get_variances <- function(data) {
  sds <- c()
  for(row in 1:nrow(data)) {
    variances <- c()
    for(col in 2:11) {
      variances <- append(variances, data[[row, col]])
    }
    sds[row] <- sd(variances)
  }
  return(sds)
}

# actually add the scores to the dataframe
append_scores <- function(data) {
  scores <- get_scores(data)
  variances <- get_variances(data)
  print(scores)
  print(variances)
  data$normalized_score=scores
  data$metaphor_variance=variances
  return(data)
}

# Aggregate the data for columns that have the 
# same metaphor measure
bucket_by_group <- function(data) {
  return (aggregate(list(X1=data$X1, 
                 X2=data$X2,
                 X3=data$X3,
                 X4=data$X4,
                 X5=data$X5,
                 X6=data$X6,
                 X7=data$X7,
                 X8=data$X8,
                 X9=data$X9,
                 X10=data$X10,
                 Total=data$Total), 
             by=list(metaphor_measure=data$metaphor_measure), 
             FUN=sum))
}
```
Sweet, now instead of dealing with survey statements we're dealing with semantic meaning. 

Just to be clear, this is what we're doing start to finish to get a nice and shiny 
bucketed dataset with new scores we can then compare based on the semantic
meanings and not the actual survey statements.
So let's transform all our old data so it's nice and bucketed, and sorted by score
```{r}
transform_data <- function(data) {
  transformed_data <- data %>%
    group_by_statement() %>%
    bucket_by_group() %>%
    append_scores() 
  return(transformed_data[rev(order(transformed_data$normalized_score)),])
}

aao <- transform_data(aao)
aas <- transform_data(aas)
aaop <- transform_data(aaop)
aao$condition <- "original"
aas$condition <- "small"
aaop$condition <- "open"

eo <- transform_data(eo)
ec <- transform_data(ec)
es <- transform_data(es)
eo$condition <- "original"
es$condition <- "separated"
ec$condition <- "chest"

uo <- transform_data(uo)
uf <- transform_data(uf)
ut <- transform_data(ut)
uo$condition <- "original"
uf$condition <- "forced"
ut$condition <- "together"
```


Let's do ourselves a favor and put these next to each other, so we have one table per
gesture, as opposed to 3. There is *for sure* a nicer way to do this but this is quick and dirty.
I'm sorry for what I've done.
```{r}
summarise_gesture <- function(orig, manip1, manip1_name, manip2, manip2_name) {
  # drop columns we don't care about
  keep = c("metaphor_measure", "normalized_score", "metaphor_variance")
  
  orig <- orig[keep] 
  colnames(orig)[2] <- "original"
  
  manip1 <- manip1[keep]
  colnames(manip1)[2] <- manip1_name
  
  manip2 <- manip2[keep]
  colnames(manip2)[2] <- manip2_name
  
  summary_table <- left_join(orig, manip1, by="metaphor_measure") %>%
    left_join(manip2, by="metaphor_measure")
}

aa_summary <- summarise_gesture(aao, 
                                aas, "small",
                                aaop, "open")
                                
entity_summary <- summarise_gesture(eo, 
                                es, "separate",
                                ec, "chest")
                                
unpolite_summary <- summarise_gesture(uo, 
                                ut, "together",
                                uf, "force")
```


Now we have nice summaries of the data, but let's make sure we have a big table too.
```{r}
scale_scores <- function(data) {
  data$X1 <- data$X1 * 10
  data$X2 <- data$X2 * 9
  data$X3 <- data$X3 * 8
  data$X4 <- data$X4 * 7
  data$X5 <- data$X5 * 6
  data$X6 <- data$X6 * 5
  data$X7 <- data$X7 * 4
  data$X8 <- data$X8 * 3
  data$X9 <- data$X9 * 2
  data$X10 <- data$X10 * 1
  return(data)
}

scale_gather_normalize <- function(data) {
  data <- scale_scores(data) %>%
    gather("ranking_position", "scaled_score", 2:11)
  data$normalized_scores <- data$scaled_score / data$Total
  return(data)
}

scale_and_normalize <- function(orig_data, cond1_data, cond1_name, cond2_data, cond2_name) {
  # scale all the scores
  orig_data <- scale_gather_normalize(orig_data) 
  cond1_data <- scale_gather_normalize(cond1_data) 
  cond2_data <- scale_gather_normalize(cond2_data) 
  
  # name it up nice
  orig_data$condition <- "original"
  cond1_data$condition <- cond1_name
  cond2_data$condition <- cond2_name
  
  #concat the datasets
  return(rbind(orig_data, cond1_data, cond2_data))
}

 total_unpolite <- scale_and_normalize(uo, ut, "together", uf, "forced")
 total_entity <- scale_and_normalize(eo, ec, "chest", es, "separated")
 total_audience <- scale_and_normalize(aao, aas, "small", aaop, "open")
```

## Plot these bad boys

### Means
For a general idea.
```{r}
unpolite_mean_plot <- ggplot(total_unpolite, aes(x=metaphor_measure, y=normalized_score, fill=condition)) + 
    geom_bar(stat="identity", position="dodge") + 
    facet_wrap(~metaphor_measure, scale="free")

audience_mean_plot <- ggplot(total_audience, aes(x=metaphor_measure, y=normalized_score, fill=condition)) + 
    geom_bar(stat="identity", position="dodge") + 
    facet_wrap(~metaphor_measure, scale="free")

entity_mean_plot <- ggplot(total_entity, aes(x=metaphor_measure, y=normalized_score, fill=condition)) + 
    geom_bar(stat="identity", position="dodge") + 
    facet_wrap(~metaphor_measure, scale="free")
```

### Densities
Now plot the densities of each response.
First make a function that creates a dataframe that reflects something slightly different in the data
```{r}
pull_ranking <- function(data) {
  data <- gather(data, "ranking", "num_ranking", 2:11)  
  data$ranking <- as.numeric(gsub("[^0-9]", "", data$ranking))
  return(data)
}

pull_rankings <- function(data1, data2, data3) {
  data1 <- pull_ranking(data1)
  data2 <- pull_ranking(data2)
  data3 <- pull_ranking(data3)
  total <- rbind(data1, data2, data3)
  return(select(total, metaphor_measure, condition, ranking, num_ranking))
}

make_density_data <- function(data) {
  new_data <- data.frame()
  for(row in 1:nrow(data)) {
    for(j in 1:data[[row,4]]) {
      new_data <- rbind(new_data, data[row,])
    }
  }
  return(new_data)
}
```

Now we can actually plot the distribution of ranked responses.
```{r}
make_density_plot <- function(data1, data2, data3) {
  plot <- ggplot(make_density_data(pull_rankings(data1, data2, data3)),
                           aes(x=ranking, fill=condition)) + 
  geom_density(alpha=0.3, stat="density", adjust=0.65) +
  facet_wrap(~metaphor_measure, scale="free")
  return(plot)
}

make_density_plot_scaled <- function(data1, data2, data3) {
  plot <- ggplot(make_density_data(pull_rankings(data1, data2, data3)),
                           aes(x=ranking, fill=condition)) + 
  geom_density(alpha=0.3, stat="density", adjust=0.65) +
  facet_wrap(~metaphor_measure, scale="fixed")
  return(plot)
}
```
#### Unpolite Density:
```{r}
unpolite_density <- make_density_plot(uo, uf, ut)
unpolite_density_scaled <- make_density_plot_scaled(uo, uf, ut)
# unpolite_density
unpolite_density_scaled
```

#### Audience Density:
```{r}
audience_density <- make_density_plot(aao, aas,aaop)
audience_density
```
#### Entity Density
```{r}
entity_density <- make_density_plot(eo, es, ec)
entity_density
```

### Plotting Range
We can also effectively plot the "range" of responses using a boxplot.
Our "outliers" are actually the most important part of our data, so let's make sure we visualize them as such:
```{r}
# define the summary function to describe our stats the way we want
f <- function(x) {
  r <- quantile(x, probs = c(0.25, 0.5, 0.75, 0.999, 0.99999))
  names(r) <- c("ymin", "lower", "middle", "upper", "ymax")
  r
}

```

And now let's graph if up real style 
```{r}
plot_range <- function(data) {
  data_plot <- ggplot(data, aes(x=metaphor_measure, y=normalized_scores, fill=condition)) + 
  stat_summary(fun.data=f, geom="boxplot", position="dodge2") + 
  facet_wrap(~metaphor_measure, scale="free")
  
  return(data_plot)
}

unpolite_range <- plot_range(total_unpolite)
audience_range <- plot_range(total_audience)
entity_range <- plot_range(total_entity)
```
#### Unpolite Range:
```{r}
unpolite_range
```
#### Audience Range:
```{r}
audience_range
```
#### Entity Range
```{r}
entity_range
```

Great, that gives a better picture of everything together


## Stats on Stats on Stats

### Power Analysis
```{r}
get_avg_participants_per_condition <- function(data1, data2, data3) {
  return(mean(c(mean(data1$Total), mean(data2$Total), mean(data3$Total))))
}
```

pwr.anova.test(k = , n = , f = , sig.level = , power = )
where k is the number of groups and n is the common sample size in each group.
For a one-way ANOVA effect size is measured by f where
Cohen suggests that f values of 0.1, 0.25, and 0.4 represent small, medium, and large effect sizes respectively.

Right now we have powers of:
```{r}
print("audience:")
pwr.anova.test(k=3, n=get_avg_participants_per_condition(aao, aas, aaop), sig.level=0.05, f=0.25)
print("entity:")
pwr.anova.test(k=3, n=get_avg_participants_per_condition(eo, es, ec), sig.level=0.05, f=0.25)
print("unpolite:")
pwr.anova.test(k=3, n=get_avg_participants_per_condition(uo, uf, ut), sig.level=0.05, f=0.25)
```
So pretty good powers, all ~90%.
