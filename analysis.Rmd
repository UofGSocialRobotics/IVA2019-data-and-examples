---
title: "IVA2019 Analysis"
author: "CSaund"
date: "2/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(pwr)
library(ordinal)
```

AA = "available audience"
E = entity
U = unpolite
O = original
AAOP = AA open
AAS = AA Small
ES = E separate
EC = E control
UT = U together
UF = U force

## Load 'N' Wrangle

Load these bad larrys
Annoyingly can't create dynamically named variables in R AFAIK, so manual
```{r}
condition_names <- c('aao', 'aas', 'aaop', 'eo','ec','es','uo','uf','ut')
aao <- read.csv('aao_2.csv')
aas <- read.csv('aas_2.csv')
aaop <- read.csv('aaop_2.csv')
eo <- read.csv('eo_2.csv')
ec <- read.csv('ec_2.csv')
es <- read.csv('es_2.csv')
uo <- read.csv('uo_2.csv')
ut <- read.csv('ut_2.csv')
uf <- read.csv('uf_2.csv')
```

First step, collapse responses into metaphor-y responses. 
1. (Force is conflict) Combine rows for "There is tension between people in the group" and "People in the group disagree with one another"
2. (Physical closeness is ideological closeness) Combine "People in this group generally get along" and "People in the group are working together to solve a problem"
3. (Abstract ideas have concrete properties (size)) "She is referring to everybody in the group" and "This group consists of many people"
4. (Open is accessible) "The speaker likes the people in the group" and "The speaker is open to feedback from the group"
5. (Being in control is being above) "The speaker is annoyed with the group" and "The speaker is in control of the group"

We add a "group"column that actually tells us what the metaphors were in reference to. 
```{r}
group_by_metaphor <- function(data) {
  data$metaphor_measure <- ""
  for(row in 1:nrow(data)) {
    if (data$Answer.Choices[row] == "People in the group are working together to solve a problem" || 
        data$Answer.Choices[row] == "People in the group generally get along") {
      data$metaphor_measure[row] <- "closeness"
    } else if (data$Answer.Choices[row] == "There is tension between people in the group" || 
               data$Answer.Choices[row] == "People in the group disagree with one another") {
      data$metaphor_measure[row] <- "conflict"
    } else if (data$Answer.Choices[row] == "She is referring to everybody in the group" || 
               data$Answer.Choices[row] == "This group consists of many people") {
      data$metaphor_measure[row] <- "size"
    } else if (data$Answer.Choices[row] == "The speaker likes the people in the group" || 
               data$Answer.Choices[row] == "The speaker is open to feedback from the group") {
      data$metaphor_measure[row] <- "open"
    } else if (data$Answer.Choices[row] == "The speaker is in annoyed with the group" || 
               data$Answer.Choices[row] == "The speaker is in control of the group") {
      data$metaphor_measure[row] <- "control"
    } else {
      # for some reason it's not recognizing the annoyed case, so let's throw it in the else
      # cause that seems safe.
      data$metaphor_measure[row] <- "control"
    }
  }
  return(data)
}

group_by_statement <- function(data) {
  data$metaphor_measure <- ""
  for(row in 1:nrow(data)) {
    if (data$Answer.Choices[row] == "People in the group are working together to solve a problem") {
               data$metaphor_measure[row] <- "WorkTogether"
    } else if (data$Answer.Choices[row] == "There is tension between people in the group") {
              data$metaphor_measure[row] <- "Tension"
    } else if (data$Answer.Choices[row] == "She is referring to everybody in the group") {
              data$metaphor_measure[row] <- "Everybody"
    } else if (data$Answer.Choices[row] == "The speaker likes the people in the group") {
              data$metaphor_measure[row] <- "Likes"
    } else if (data$Answer.Choices[row] == "The speaker is in annoyed with the group") {
              data$metaphor_measure[row] <- "Annoyed"
    } else if (data$Answer.Choices[row] == "People in the group generally get along") {
              data$metaphor_measure[row] <- "GetAlong"
    } else if (data$Answer.Choices[row] == "People in the group disagree with one another") {
               data$metaphor_measure[row] <- "Disagree"
    } else if (data$Answer.Choices[row] == "This group consists of many people") {
              data$metaphor_measure[row] <- "ManyPeople"
    } else if (data$Answer.Choices[row] == "The speaker is open to feedback from the group") {
      data$metaphor_measure[row] <- "Feedback"
    } else if (data$Answer.Choices[row] == "The speaker is in control of the group") {
              data$metaphor_measure[row] <- "Control"
    } else {
      # for some reason it's not recognizing the annoyed case, so let's throw it in the else
      # cause that seems safe.
      data$metaphor_measure[row] <- "Annoyed"
    }
  }
  return(data)
}
```

This means we're gonna have to calculate our own scores
```{r}
# Get all the overall scores (mean for condition) for a dataset
get_scores <- function(data) {
  scores <- c()
  for(row in 1:nrow(data)) {
    total_score = 0
    for(col in 2:11) {
      total_score = total_score + data[row,col] * (12 - col)
    }
    scores[row] <- (total_score / data[row,12])
  }
  return(scores)
}

# variances while we're at it too
get_variances <- function(data) {
  sds <- c()
  for(row in 1:nrow(data)) {
    variances <- c()
    for(col in 2:11) {
      variances <- append(variances, data[[row, col]])
    }
    sds[row] <- sd(variances)
  }
  return(sds)
}

# actually add the scores to the dataframe
append_scores <- function(data) {
  scores <- get_scores(data)
  variances <- get_variances(data)
  print(scores)
  print(variances)
  data$normalized_score=scores
  data$metaphor_variance=variances
  return(data)
}

# Aggregate the data for columns that have the 
# same metaphor measure
bucket_by_group <- function(data) {
  return (aggregate(list(X1=data$X1, 
                 X2=data$X2,
                 X3=data$X3,
                 X4=data$X4,
                 X5=data$X5,
                 X6=data$X6,
                 X7=data$X7,
                 X8=data$X8,
                 X9=data$X9,
                 X10=data$X10,
                 Total=data$Total), 
             by=list(metaphor_measure=data$metaphor_measure), 
             FUN=sum))
}
```
Sweet, now instead of dealing with survey statements we're dealing with semantic meaning. 

Just to be clear, this is what we're doing start to finish to get a nice and shiny 
bucketed dataset with new scores we can then compare based on the semantic
meanings and not the actual survey statements.
So let's transform all our old data so it's nice and bucketed, and sorted by score
```{r}
transform_data <- function(data) {
  transformed_data <- data %>%
    group_by_statement() %>%
    bucket_by_group() %>%
    append_scores() 
  return(transformed_data[rev(order(transformed_data$normalized_score)),])
}

aao <- transform_data(aao)
aas <- transform_data(aas)
aaop <- transform_data(aaop)
aao$condition <- "original"
aas$condition <- "small"
aaop$condition <- "open"

eo <- transform_data(eo)
ec <- transform_data(ec)
es <- transform_data(es)
eo$condition <- "original"
es$condition <- "separated"
ec$condition <- "chest"

uo <- transform_data(uo)
uf <- transform_data(uf)
ut <- transform_data(ut)
uo$condition <- "original"
uf$condition <- "forced"
ut$condition <- "together"
```


Let's do ourselves a favor and put these next to each other, so we have one table per
gesture, as opposed to 3. There is *for sure* a nicer way to do this but this is quick and dirty.
I'm sorry for what I've done.
```{r}
summarise_gesture <- function(orig, manip1, manip1_name, manip2, manip2_name) {
  # drop columns we don't care about
  keep = c("metaphor_measure", "normalized_score", "metaphor_variance")
  
  orig <- orig[keep] 
  colnames(orig)[2] <- "original"
  
  manip1 <- manip1[keep]
  colnames(manip1)[2] <- manip1_name
  
  manip2 <- manip2[keep]
  colnames(manip2)[2] <- manip2_name
  
  summary_table <- left_join(orig, manip1, by="metaphor_measure") %>%
    left_join(manip2, by="metaphor_measure")
}

aa_summary <- summarise_gesture(aao, 
                                aas, "small",
                                aaop, "open")
                                
entity_summary <- summarise_gesture(eo, 
                                es, "separate",
                                ec, "chest")
                                
unpolite_summary <- summarise_gesture(uo, 
                                ut, "together",
                                uf, "force")
```


Now we have nice summaries of the data, but let's make sure we have a big table too.
```{r}
scale_scores <- function(data) {
  data$X1 <- data$X1 * 10
  data$X2 <- data$X2 * 9
  data$X3 <- data$X3 * 8
  data$X4 <- data$X4 * 7
  data$X5 <- data$X5 * 6
  data$X6 <- data$X6 * 5
  data$X7 <- data$X7 * 4
  data$X8 <- data$X8 * 3
  data$X9 <- data$X9 * 2
  data$X10 <- data$X10 * 1
  return(data)
}

scale_gather_normalize <- function(data) {
  data <- scale_scores(data) %>%
    gather("ranking_position", "scaled_score", 2:11)
  data$normalized_scores <- data$scaled_score / data$Total
  return(data)
}

scale_and_normalize <- function(orig_data, cond1_data, cond1_name, cond2_data, cond2_name) {
  # scale all the scores
  orig_data <- scale_gather_normalize(orig_data) 
  cond1_data <- scale_gather_normalize(cond1_data) 
  cond2_data <- scale_gather_normalize(cond2_data) 
  
  # name it up nice
  orig_data$condition <- "original"
  cond1_data$condition <- cond1_name
  cond2_data$condition <- cond2_name
  
  #concat the datasets
  return(rbind(orig_data, cond1_data, cond2_data))
}

 total_unpolite <- scale_and_normalize(uo, ut, "together", uf, "forced")
 total_entity <- scale_and_normalize(eo, ec, "chest", es, "separated")
 total_audience <- scale_and_normalize(aao, aas, "small", aaop, "open")
```

## Plot these bad boys

### Means
For a general idea.
```{r}
unpolite_mean_plot <- ggplot(total_unpolite, aes(x=metaphor_measure, y=normalized_score, fill=condition)) + 
    geom_bar(stat="identity", position="dodge") + 
    facet_wrap(~metaphor_measure, scale="free")

audience_mean_plot <- ggplot(total_audience, aes(x=metaphor_measure, y=normalized_score, fill=condition)) + 
    geom_bar(stat="identity", position="dodge") + 
    facet_wrap(~metaphor_measure, scale="free")

entity_mean_plot <- ggplot(total_entity, aes(x=metaphor_measure, y=normalized_score, fill=condition)) + 
    geom_bar(stat="identity", position="dodge") + 
    facet_wrap(~metaphor_measure, scale="free")
```

### Densities
Now plot the densities of each response.
First make a function that creates a dataframe that reflects something slightly different in the data
```{r}
pull_ranking <- function(data) {
  data <- gather(data, "ranking", "num_ranking", 2:11)  
  data$ranking <- as.numeric(gsub("[^0-9]", "", data$ranking))
  return(data)
}

pull_rankings <- function(data1, data2, data3) {
  data1 <- pull_ranking(data1)
  data2 <- pull_ranking(data2)
  data3 <- pull_ranking(data3)
  total <- rbind(data1, data2, data3)
  return(select(total, metaphor_measure, condition, ranking, num_ranking))
}

make_density_data <- function(data) {
  new_data <- data.frame()
  for(row in 1:nrow(data)) {
    for(j in 1:data[[row,4]]) {
      new_data <- rbind(new_data, data[row,])
    }
  }
  return(new_data)
}
```

Now we can actually plot the distribution of ranked responses.
```{r}
make_density_plot <- function(data1, data2, data3) {
  plot <- ggplot(make_density_data(pull_rankings(data1, data2, data3)),
                           aes(x=ranking, fill=condition)) + 
  geom_density(alpha=0.3, stat="density", adjust=0.65) +
  facet_wrap(~metaphor_measure, scale="free")
  return(plot)
}

make_density_plot_scaled <- function(data1, data2, data3) {
  plot <- ggplot(make_density_data(pull_rankings(data1, data2, data3)),
                           aes(x=ranking, fill=condition)) + 
  geom_density(alpha=0.3, stat="density", adjust=0.65) +
  facet_wrap(~metaphor_measure, scale="fixed")
  return(plot)
}
```
#### Unpolite Density:
```{r}
unpolite_density <- make_density_plot(uo, uf, ut)
unpolite_density_scaled <- make_density_plot_scaled(uo, uf, ut)
unpolite_density
ggsave("unpolite_density.png", unpolite_density, width=8, height=5)
unpolite_density_scaled
```
#### Audience Density:
```{r}
audience_density <- make_density_plot(aao, aas,aaop)
audience_density
```
#### Entity Density
```{r}
entity_density <- make_density_plot(eo, es, ec)
entity_density
```

### Plotting Range
We can also effectively plot the "range" of responses using a boxplot.
Our "outliers" are actually the most important part of our data, so let's make sure we visualize them as such:
```{r}
# define the summary function to describe our stats the way we want
f <- function(x) {
  r <- quantile(x, probs = c(0.25, 0.5, 0.75, 0.999, 0.99999))
  names(r) <- c("ymin", "lower", "middle", "upper", "ymax")
  r
}

```

And now let's graph if up real style 
```{r}
plot_range <- function(data) {
  data_plot <- ggplot(data, aes(x=metaphor_measure, y=normalized_scores, fill=condition)) + 
  stat_summary(fun.data=f, geom="boxplot", position="dodge2") + 
  facet_wrap(~metaphor_measure, scale="free")
  
  return(data_plot)
}

unpolite_range <- plot_range(total_unpolite)
audience_range <- plot_range(total_audience)
entity_range <- plot_range(total_entity)
```
#### Unpolite Range:
```{r}
unpolite_range
```
#### Audience Range:
```{r}
audience_range
```
#### Entity Range
```{r}
entity_range
```

Great, that gives a better picture of everything together


## Stats on Stats on Stats

### Power Analysis
```{r}
get_avg_participants_per_condition <- function(data1, data2, data3) {
  return(mean(c(mean(data1$Total), mean(data2$Total), mean(data3$Total))))
}
```

pwr.anova.test(k = , n = , f = , sig.level = , power = )
where k is the number of groups and n is the common sample size in each group.
For a one-way ANOVA effect size is measured by f where
Cohen suggests that f values of 0.1, 0.25, and 0.4 represent small, medium, and large effect sizes respectively.

Right now we have powers of:
```{r}
print("audience:")
pwr.anova.test(k=3, n=get_avg_participants_per_condition(aao, aas, aaop), sig.level=0.05, f=0.25)
print("entity:")
pwr.anova.test(k=3, n=get_avg_participants_per_condition(eo, es, ec), sig.level=0.05, f=0.25)
print("unpolite:")
pwr.anova.test(k=3, n=get_avg_participants_per_condition(uo, uf, ut), sig.level=0.05, f=0.25)
```
So pretty good powers, all ~90%.

### Effects of Condition on Metaphoric Interpretation
Let's check to see, for example, how much the variation in 'closeness' is dependent on our condition

I want to know the effect of the condition on the scores by metaphor
```{r}
## Code the categorical variables
code_metaphors <- function(data) {
  dummy_data <- data
  for(row in 1:nrow(data)){
    if(dummy_data[[row, 1]] == 'closeness') {
      dummy_data[[row, 1]] <- 0
    } else if (dummy_data[[row, 1]] == 'control'){
      dummy_data[[row, 1]] <- 1
    } else if (dummy_data[[row, 1]] == 'size'){
      dummy_data[[row, 1]] <- 2
    } else if (dummy_data[[row, 1]] == 'open'){
      dummy_data[[row, 1]] <- 3
    } else if (dummy_data[[row, 1]] == 'conflict'){
      dummy_data[[row, 1]] <- 4
    }
  }
  return(dummy_data)
}

## Code the categorical variables
code_conditions <- function(data) {
  dummy_data <- data
  for(row in 1:nrow(data)){
    if(dummy_data[[row, 5]] == 'original') {
      dummy_data[[row, 5]] <- 0
    } else if (dummy_data[[row, 5]] == 'forced'){
      dummy_data[[row, 5]] <- 1
    } else if (dummy_data[[row, 5]] == 'together'){
      dummy_data[[row, 5]] <- 2
    }
  }
  return(dummy_data)
}

u_dummy <- code_metaphors(total_unpolite)
u_dummy <- code_conditions(u_dummy)

a_dummy <- code_metaphors(total_audience)
a_dummy <- code_conditions(a_dummy)

e_dummy <- code_metaphors(total_entity)
e_dummy <- code_conditions(e_dummy)

u_control <- lm(condition ~ metaphor_measure * normalized_score, data=u_dummy)
summary(u_control)

## almost certain this is correct
u_t <- lm(normalized_scores ~ metaphor_measure:condition, data=filter(total_unpolite, metaphor_measure=='conflict'))
summary(u_t)

a_t <- lm(normalized_scores ~ metaphor_measure:condition, data=a_dummy)
summary(a_t)

e_t <- lm(normalized_scores ~ metaphor_measure:condition, data=e_dummy)
summary(e_t)
```

Basically the answer is... not much. But we can try for all of the different conditions.
```{r}
generate_anovas <- function(data) {
  print('closeness, conflict, control, open, size')
  print(summary(generate_anova(data, 'closeness')))
  print(summary(generate_anova(data, 'conflict')))
  print(summary(generate_anova(data, 'control')))
  print(summary(generate_anova(data,'open')))
  print(summary(generate_anova(data,'size')))
}

generate_anovas_by_mean <- function(data) {
  print('closeness, conflict, control, open, size')
  print(summary(generate_anova_by_mean(data, 'closeness')))
  print(summary(generate_anova_by_mean(data, 'conflict')))
  print(summary(generate_anova_by_mean(data, 'control')))
  print(summary(generate_anova_by_mean(data,'open')))
  print(summary(generate_anova_by_mean(data,'size')))
}

# not particularly useful up above, but handy for having during test period. 
generate_anova <- function(data, metaphor_filter) {
  return(aov(normalized_scores ~ condition, data=filter(data, metaphor_measure==metaphor_filter)))
}

generate_anova_by_mean <- function(data, metaphor_filter) {
  # normalized SCORE not normalized scoreS
  return(aov(normalized_score ~ condition, data=filter(data, metaphor_measure==metaphor_filter)))
}
```

```{r}
print('unpolite')
generate_anovas(total_unpolite)
```

```{r}
print('audience')
generate_anovas(total_audience)
```

```{r}
print('entity')
generate_anovas(total_entity)
```


### Ordinal Models
We need to factor things often.
```{r}
factor_normalized_scores <- function(data) {
  factored <- data
  factored$normalized_scores <- factor(factored$normalized_scores)
  return(factored)
}
```

Now try doing ordinal ranked response analysis
```{r}
t <- total_unpolite
t$normalized_scores <- factor(t$normalized_scores)
t <- factor_normalized_scores(total_unpolite)

factored_unpolite <- factor_normalized_scores(total_unpolite)
ordinal_mod <- clm(condition ~ metaphor_measure * normalized_scores, data=t)
ordinal_mod_no_cond <- clm(num_ranking ~ metaphor_measure * condition - condition, data=factor_normalized_score(total_unpolite))
anova(ordinal_mod, ordinal_mod_no_cond)
summary(ordinal_mod)
```

### Bootstrapping the ~Data~
Now let's try bootstrapping this bad boy
```{r}
generate_bootstrapped_data <- function(data, n) {
  generated_data <- data[0,]
  for(i in 1:n) {
    generated_data <- rbind(generated_data, sample_n(data, 1))
  }
  return(generated_data)
}
```

Perhaps fortunately, perhaps not, this brings significance values wayyyyy up. Let's compare:
```{r}
unpolite_bootstrapped <- generate_bootstrapped_data(total_unpolite, 150)
print('unpolite')
generate_anovas(unpolite_bootstrapped)
```

```{r}
audience_bootstrapped <- generate_bootstrapped_data(total_audience, 150)
print('audience')
generate_anovas(audience_bootstrapped)
```

```{r}
entity_bootstrapped <- generate_bootstrapped_data(total_entity, 150)
print('entity')
generate_anovas(entity_bootstrapped)
```



## Show Me What Matters
Fine, I will. 

```{r}
## Make it pretty
print_anova_significance <- function(data) {
  print('closeness')
  print(summary(generate_anova(data, 'closeness'))[[1]][["Pr(>F)"]][1])
  print('conflict')
  print(summary(generate_anova(data, 'conflict'))[[1]][["Pr(>F)"]][1])
  print('control')
  print(summary(generate_anova(data, 'control'))[[1]][["Pr(>F)"]][1])
  print('open')
  print(summary(generate_anova(data,'open'))[[1]][["Pr(>F)"]][1])
  print('size')
  print(summary(generate_anova(data,'size'))[[1]][["Pr(>F)"]][1])
}
```
Now we need to actually average the p values from bootstrapping
```{r}
## Do it a buncha times
average_p <- function(data, metaphor_measure, n) {
  avg_measure <- c()
  for(i in 1:n) {
    bootstrapped_data <- generate_bootstrapped_data(data, 150)
    bootstrapped_p <- summary(generate_anova(bootstrapped_data, metaphor_measure))[[1]][["Pr(>F)"]][1]
    avg_measure <- c(avg_measure, bootstrapped_p)
  }
  return(mean(avg_measure))
}

average_ps <- function(data, n) {
  print('closeness')
  print(average_p(data, 'closeness', n))
  print('control')
  print(average_p(data, 'control', n))
  print('size')
  print(average_p(data, 'size', n))
  print('open')
  print(average_p(data, 'open', n))
  print('conflict')
  print(average_p(data, 'conflict', n))
}
```


# "Unpolite"
```{r}
print_anova_significance(total_unpolite)
plot_the_thing(total_unpolite)
# average p values of BOOTSTRAPPED data
# average_ps(total_unpolite, 100)
```


# "Available Audience"
```{r}
print_anova_significance(total_audience)
plot_the_thing(total_audience)
# average p values of BOOTSTRAPPED data
# average_ps(total_audience, 100)
```

# "Entity"
```{r}
print_anova_significance(total_entity)
plot_the_thing(total_entity)
# average p values of BOOTSTRAPPED data
# average_ps(total_entity, 100)
```


### Other Exploratory Analyses
#### 1. Just look at top three metaphors for each condition
```{r}
compare <- function(orig, manip1, manip2) {
  original <- orig$metaphor_measure[1:3]
  manip1 <- manip1$metaphor_measure[1:3]
  manip2 <- manip2$metaphor_measure[1:3]
  df <- data.frame(original, manip1, manip2)
  return(df)
}
```

#### 2. Look at variances of metaphors for each condition
Looks like there's really not much to it. Weak correlation at best.
Checking the rsq:
```{r}
rsq <- function(x, y) {
  cor(x, y)  ^ 2
}

rsq(total_unpolite$normalized_score, total_unpolite$metaphor_variance)
rsq(total_audience$normalized_score, total_audience$metaphor_variance)
rsq(total_entity$normalized_score, total_entity$metaphor_variance)

# But what about when we BOOTSTRAP IT
rsq_bootstrapped <- function(data, n) {
  avg_measure <- c()
  for(i in 1:n) {
    bootstrapped_data <- generate_bootstrapped_data(data, 15)
    bootstrapped_rsq <- rsq(data$normalized_score, data$metaphor_variance)
    avg_measure <- c(avg_measure, bootstrapped_rsq)
  }
  return(mean(avg_measure))  
}

rsq_bootstrapped(total_unpolite, 100)
rsq_bootstrapped(total_audience, 100)
rsq_bootstrapped(total_entity, 100)
```
lol terrible. 

#### 3. Bootstrap based on the means
```{r}
# messy but bootstrapping based on means means we gotta do it
test_p_bootstrap_by_means <- function(data, metaphor_measure, n) {
  avg_measure <- c()
  for(i in 1:n) {
    bootstrapped_data <- generate_bootstrapped_data(data, 50)
    bootstrapped_p <- summary(generate_anova_by_mean(bootstrapped_data, metaphor_measure))[[1]][["Pr(>F)"]][1]
    avg_measure <- c(avg_measure, bootstrapped_p)
  }
  return(mean(avg_measure))  
}

#test_p_bootstrap_by_means(total_unpolite, "control", 100)
```
OK this doesn't work because we have such a small amount of data (means) that we're basically
guaranteed to sample all of them.



I just realized all my analysis is wrong. I'm looking at mean ranges, essentially. I need
to be looking at densities by group. Explore density plots with normalized score.

Use grouped original data maybe? And look at densities?

Need to manipulate data to reconstruct participant rankings
** Dummy code one group at a time to see effects of only one group**?
Turn ranking into scores

















###### Christoph's Help
I want to know the effect of the condition on the scores by metaphor

1. Mean center the conditions (and measures?) to determine main effects
2. Dummy code by condition to determine simple effects of each condition
   on each measure.
```{r}
## Mean centering total_unpolite
# a1 = original
# a2 = forced
# a3 = together

# b1 = closeness
# b2 = size
# b3 = conflict
# b4 = open
# b5 = control
total_unpolite$a1a2 <- scale(ifelse(total_unpolite$condition=="forced", 1, 0), center=TRUE, scale=FALSE)
total_unpolite$a1a3 <- scale(ifelse(total_unpolite$condition=="together", 1, 0), center=TRUE, scale=FALSE)
total_unpolite$dummy_original <- ifelse(total_unpolite$condition=="original", 1, 0)
total_unpolite$dummy_forced <- ifelse(total_unpolite$condition=="forced", 1, 0)
total_unpolite$dummy_together <- ifelse(total_unpolite$condition=="together", 1, 0)

total_unpolite$b1b2 <- scale(ifelse(total_unpolite$metaphor_measure=="size", 1, 0), center=TRUE, scale=FALSE)
total_unpolite$b1b3 <- scale(ifelse(total_unpolite$metaphor_measure=="conflict", 1, 0), center=TRUE, scale=FALSE)
total_unpolite$b1b4 <- scale(ifelse(total_unpolite$metaphor_measure=="open", 1, 0), center=TRUE, scale=FALSE)
total_unpolite$b1b5 <- scale(ifelse(total_unpolite$metaphor_measure=="control", 1, 0), center=TRUE, scale=FALSE)

orig_mod <- lm(normalized_scores ~ a1a2 + a1a3 + b1b2 + b1b3 + b1b4 + b1b5 +
                                  a1a2:b1b2 + a1a2:b1b3 + a1a2:b1b4 + a1a2:b1b5 +
                                  a1a3:b1b2 + a1a3:b1b3 + a1a3:b1b4 + a1a3:b1b5, data=total_unpolite)
summary(orig_mod)

orig_mod_no_a1 <- lm(normalized_scores ~ b1b2 + b1b3 + b1b4 + b1b5 +
                                  a1a2:b1b2 + a1a2:b1b3 + a1a2:b1b4 + a1a2:b1b5 +
                                  a1a3:b1b2 + a1a3:b1b3 + a1a3:b1b4 + a1a3:b1b5, data=total_unpolite)
summary(orig_mod_no_a1)
anova(orig_mod, orig_mod_no_a1)

forced_mod <- lm(normalized_scores ~ a1a2 + a1a3 + b1b2 + b1b3 + b1b4 + b1b5 +
                                  a1a2:b1b2 + a1a2:b1b3 + a1a2:b1b4 + a1a2:b1b5 +
                                  a1a3:b1b2 + a1a3:b1b3 + a1a3:b1b4 + a1a3:b1b5, data=total_unpolite)
summary(forced_mod)

together_mod <- lm(normalized_scores ~ a1a2 + a1a3 + b1b2 + b1b3 + b1b4 + b1b5 +
                                  a1a2:b1b2 + a1a2:b1b3 + a1a2:b1b4 + a1a2:b1b5 +
                                  a1a3:b1b2 + a1a3:b1b3 + a1a3:b1b4 + a1a3:b1b5, data=total_unpolite)
summary(together_mod)


# dummy coding each thing
forced_mod <- lm(normalized_scores ~ dummy_forced * metaphor_measure, data=total_unpolite)
summary(forced_mod)
together_mod <- lm(normalized_scores ~ dummy_together * metaphor_measure, data=total_unpolite)
summary(together_mod)
orig_mod <- lm(normalized_scores ~ dummy_original * metaphor_measure, data=total_unpolite)
summary(orig_mod)

## Code the categorical variables
code_metaphors <- function(data) {
  dummy_data <- data
  for(row in 1:nrow(data)){
    if(dummy_data[[row, 1]] == 'closeness') {
      dummy_data[[row, 1]] <- 0
    } else if (dummy_data[[row, 1]] == 'control'){
      dummy_data[[row, 1]] <- 1
    } else if (dummy_data[[row, 1]] == 'size'){
      dummy_data[[row, 1]] <- 2
    } else if (dummy_data[[row, 1]] == 'open'){
      dummy_data[[row, 1]] <- 3
    } else if (dummy_data[[row, 1]] == 'conflict'){
      dummy_data[[row, 1]] <- 4
    }
  }
  return(dummy_data)
}

## Code the categorical variables
code_conditions <- function(data) {
  dummy_data <- data
  for(row in 1:nrow(data)){
    if(dummy_data[[row, 5]] == 'original') {
      dummy_data[[row, 5]] <- 0
    } else if (dummy_data[[row, 5]] == 'forced'){
      dummy_data[[row, 5]] <- 1
    } else if (dummy_data[[row, 5]] == 'together'){
      dummy_data[[row, 5]] <- 2
    }
  }
  return(dummy_data)
}

u_dummy <- code_metaphors(total_unpolite)
u_dummy <- code_conditions(u_dummy)

a_dummy <- code_metaphors(total_audience)
a_dummy <- code_conditions(a_dummy)

e_dummy <- code_metaphors(total_entity)
e_dummy <- code_conditions(e_dummy)

u_control <- lm(condition ~ metaphor_measure * normalized_score, data=u_dummy)
summary(u_control)

## almost certain this is correct
u_t <- lm(normalized_scores ~ metaphor_measure:condition, data=filter(total_unpolite, metaphor_measure=='conflict'))
summary(u_t)

a_t <- lm(normalized_scores ~ metaphor_measure:condition, data=a_dummy)
summary(a_t)

e_t <- lm(normalized_scores ~ metaphor_measure:condition, data=e_dummy)
summary(e_t)
```


Wilcox signed rank compare each gesture to original for each condition
```{r}
forced_disagree <- total_unpolite %>%
  filter(metaphor_measure == "Disagree") %>%
  filter(condition == "forced")

original_disagree <- total_unpolite %>%
  filter(metaphor_measure == "Disagree") %>%
  filter(condition == "original")

res <- wilcox.test(forced_disagree$normalized_scores, original_disagree$normalized_scores)
res

ttest<- t.test(forced_disagree$normalized_scores, original_disagree$normalized_scores)
ttest
```





