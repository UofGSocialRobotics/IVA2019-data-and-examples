
## Show Me What Matters
Fine, I will. 

```{r}
## Make it pretty
print_anova_significance <- function(data) {
  print('closeness')
  print(summary(generate_anova(data, 'closeness'))[[1]][["Pr(>F)"]][1])
  print('conflict')
  print(summary(generate_anova(data, 'conflict'))[[1]][["Pr(>F)"]][1])
  print('control')
  print(summary(generate_anova(data, 'control'))[[1]][["Pr(>F)"]][1])
  print('open')
  print(summary(generate_anova(data,'open'))[[1]][["Pr(>F)"]][1])
  print('size')
  print(summary(generate_anova(data,'size'))[[1]][["Pr(>F)"]][1])
}
```
Now we need to actually average the p values from bootstrapping
```{r}
## Do it a buncha times
average_p <- function(data, metaphor_measure, n) {
  avg_measure <- c()
  for(i in 1:n) {
    bootstrapped_data <- generate_bootstrapped_data(data, 150)
    bootstrapped_p <- summary(generate_anova(bootstrapped_data, metaphor_measure))[[1]][["Pr(>F)"]][1]
    avg_measure <- c(avg_measure, bootstrapped_p)
  }
  return(mean(avg_measure))
}

average_ps <- function(data, n) {
  print('closeness')
  print(average_p(data, 'closeness', n))
  print('control')
  print(average_p(data, 'control', n))
  print('size')
  print(average_p(data, 'size', n))
  print('open')
  print(average_p(data, 'open', n))
  print('conflict')
  print(average_p(data, 'conflict', n))
}
```


# "Unpolite"
```{r}
print_anova_significance(total_unpolite)
plot_the_thing(total_unpolite)
# average p values of BOOTSTRAPPED data
# average_ps(total_unpolite, 100)
```


# "Available Audience"
```{r}
print_anova_significance(total_audience)
plot_the_thing(total_audience)
# average p values of BOOTSTRAPPED data
# average_ps(total_audience, 100)
```

# "Entity"
```{r}
print_anova_significance(total_entity)
plot_the_thing(total_entity)
# average p values of BOOTSTRAPPED data
# average_ps(total_entity, 100)
```


### Other Exploratory Analyses
#### 1. Just look at top three metaphors for each condition
```{r}
compare <- function(orig, manip1, manip2) {
  original <- orig$metaphor_measure[1:3]
  manip1 <- manip1$metaphor_measure[1:3]
  manip2 <- manip2$metaphor_measure[1:3]
  df <- data.frame(original, manip1, manip2)
  return(df)
}
```

#### 2. Look at variances of metaphors for each condition
Looks like there's really not much to it. Weak correlation at best.
Checking the rsq:
```{r}
rsq <- function(x, y) {
  cor(x, y)  ^ 2
}

rsq(total_unpolite$normalized_score, total_unpolite$metaphor_variance)
rsq(total_audience$normalized_score, total_audience$metaphor_variance)
rsq(total_entity$normalized_score, total_entity$metaphor_variance)

# But what about when we BOOTSTRAP IT
rsq_bootstrapped <- function(data, n) {
  avg_measure <- c()
  for(i in 1:n) {
    bootstrapped_data <- generate_bootstrapped_data(data, 15)
    bootstrapped_rsq <- rsq(data$normalized_score, data$metaphor_variance)
    avg_measure <- c(avg_measure, bootstrapped_rsq)
  }
  return(mean(avg_measure))  
}

rsq_bootstrapped(total_unpolite, 100)
rsq_bootstrapped(total_audience, 100)
rsq_bootstrapped(total_entity, 100)
```
lol terrible. 

#### 3. Bootstrap based on the means
```{r}
# messy but bootstrapping based on means means we gotta do it
test_p_bootstrap_by_means <- function(data, metaphor_measure, n) {
  avg_measure <- c()
  for(i in 1:n) {
    bootstrapped_data <- generate_bootstrapped_data(data, 50)
    bootstrapped_p <- summary(generate_anova_by_mean(bootstrapped_data, metaphor_measure))[[1]][["Pr(>F)"]][1]
    avg_measure <- c(avg_measure, bootstrapped_p)
  }
  return(mean(avg_measure))  
}

#test_p_bootstrap_by_means(total_unpolite, "control", 100)
```
OK this doesn't work because we have such a small amount of data (means) that we're basically
guaranteed to sample all of them.



I just realized all my analysis is wrong. I'm looking at mean ranges, essentially. I need
to be looking at densities by group. Explore density plots with normalized score.

Use grouped original data maybe? And look at densities?

Need to manipulate data to reconstruct participant rankings
** Dummy code one group at a time to see effects of only one group**?
Turn ranking into scores

















###### Christoph's Help
I want to know the effect of the condition on the scores by metaphor

1. Mean center the conditions (and measures?) to determine main effects
2. Dummy code by condition to determine simple effects of each condition
   on each measure.
```{r}
## Mean centering total_unpolite
# a1 = original
# a2 = forced
# a3 = together

# b1 = closeness
# b2 = size
# b3 = conflict
# b4 = open
# b5 = control
total_unpolite$a1a2 <- scale(ifelse(total_unpolite$condition=="forced", 1, 0), center=TRUE, scale=FALSE)
total_unpolite$a1a3 <- scale(ifelse(total_unpolite$condition=="together", 1, 0), center=TRUE, scale=FALSE)
total_unpolite$dummy_original <- ifelse(total_unpolite$condition=="original", 1, 0)
total_unpolite$dummy_forced <- ifelse(total_unpolite$condition=="forced", 1, 0)
total_unpolite$dummy_together <- ifelse(total_unpolite$condition=="together", 1, 0)

total_unpolite$b1b2 <- scale(ifelse(total_unpolite$metaphor_measure=="size", 1, 0), center=TRUE, scale=FALSE)
total_unpolite$b1b3 <- scale(ifelse(total_unpolite$metaphor_measure=="conflict", 1, 0), center=TRUE, scale=FALSE)
total_unpolite$b1b4 <- scale(ifelse(total_unpolite$metaphor_measure=="open", 1, 0), center=TRUE, scale=FALSE)
total_unpolite$b1b5 <- scale(ifelse(total_unpolite$metaphor_measure=="control", 1, 0), center=TRUE, scale=FALSE)

orig_mod <- lm(normalized_scores ~ a1a2 + a1a3 + b1b2 + b1b3 + b1b4 + b1b5 +
                                  a1a2:b1b2 + a1a2:b1b3 + a1a2:b1b4 + a1a2:b1b5 +
                                  a1a3:b1b2 + a1a3:b1b3 + a1a3:b1b4 + a1a3:b1b5, data=total_unpolite)
summary(orig_mod)

orig_mod_no_a1 <- lm(normalized_scores ~ b1b2 + b1b3 + b1b4 + b1b5 +
                                  a1a2:b1b2 + a1a2:b1b3 + a1a2:b1b4 + a1a2:b1b5 +
                                  a1a3:b1b2 + a1a3:b1b3 + a1a3:b1b4 + a1a3:b1b5, data=total_unpolite)
summary(orig_mod_no_a1)
anova(orig_mod, orig_mod_no_a1)

forced_mod <- lm(normalized_scores ~ a1a2 + a1a3 + b1b2 + b1b3 + b1b4 + b1b5 +
                                  a1a2:b1b2 + a1a2:b1b3 + a1a2:b1b4 + a1a2:b1b5 +
                                  a1a3:b1b2 + a1a3:b1b3 + a1a3:b1b4 + a1a3:b1b5, data=total_unpolite)
summary(forced_mod)

together_mod <- lm(normalized_scores ~ a1a2 + a1a3 + b1b2 + b1b3 + b1b4 + b1b5 +
                                  a1a2:b1b2 + a1a2:b1b3 + a1a2:b1b4 + a1a2:b1b5 +
                                  a1a3:b1b2 + a1a3:b1b3 + a1a3:b1b4 + a1a3:b1b5, data=total_unpolite)
summary(together_mod)


# dummy coding each thing
forced_mod <- lm(normalized_scores ~ dummy_forced * metaphor_measure, data=total_unpolite)
summary(forced_mod)
together_mod <- lm(normalized_scores ~ dummy_together * metaphor_measure, data=total_unpolite)
summary(together_mod)
orig_mod <- lm(normalized_scores ~ dummy_original * metaphor_measure, data=total_unpolite)
summary(orig_mod)

## Code the categorical variables
code_metaphors <- function(data) {
  dummy_data <- data
  for(row in 1:nrow(data)){
    if(dummy_data[[row, 1]] == 'closeness') {
      dummy_data[[row, 1]] <- 0
    } else if (dummy_data[[row, 1]] == 'control'){
      dummy_data[[row, 1]] <- 1
    } else if (dummy_data[[row, 1]] == 'size'){
      dummy_data[[row, 1]] <- 2
    } else if (dummy_data[[row, 1]] == 'open'){
      dummy_data[[row, 1]] <- 3
    } else if (dummy_data[[row, 1]] == 'conflict'){
      dummy_data[[row, 1]] <- 4
    }
  }
  return(dummy_data)
}

## Code the categorical variables
code_conditions <- function(data) {
  dummy_data <- data
  for(row in 1:nrow(data)){
    if(dummy_data[[row, 5]] == 'original') {
      dummy_data[[row, 5]] <- 0
    } else if (dummy_data[[row, 5]] == 'forced'){
      dummy_data[[row, 5]] <- 1
    } else if (dummy_data[[row, 5]] == 'together'){
      dummy_data[[row, 5]] <- 2
    }
  }
  return(dummy_data)
}

u_dummy <- code_metaphors(total_unpolite)
u_dummy <- code_conditions(u_dummy)

a_dummy <- code_metaphors(total_audience)
a_dummy <- code_conditions(a_dummy)

e_dummy <- code_metaphors(total_entity)
e_dummy <- code_conditions(e_dummy)

u_control <- lm(condition ~ metaphor_measure * normalized_score, data=u_dummy)
summary(u_control)

## almost certain this is correct
u_t <- lm(normalized_scores ~ metaphor_measure:condition, data=filter(total_unpolite, metaphor_measure=='conflict'))
summary(u_t)

a_t <- lm(normalized_scores ~ metaphor_measure:condition, data=a_dummy)
summary(a_t)

e_t <- lm(normalized_scores ~ metaphor_measure:condition, data=e_dummy)
summary(e_t)
```


Wilcox signed rank compare each gesture to original for each condition
```{r}
forced_disagree <- total_unpolite %>%
  filter(metaphor_measure == "Disagree") %>%
  filter(condition == "forced")

original_disagree <- total_unpolite %>%
  filter(metaphor_measure == "Disagree") %>%
  filter(condition == "original")

res <- wilcox.test(forced_disagree$normalized_scores, original_disagree$normalized_scores)
res

ttest<- t.test(forced_disagree$normalized_scores, original_disagree$normalized_scores)
ttest
```



### Effects of Condition on Metaphoric Interpretation
Let's check to see, for example, how much the variation in 'closeness' is dependent on our condition

I want to know the effect of the condition on the scores by metaphor
```{r}
## Code the categorical variables
code_metaphors <- function(data) {
  dummy_data <- data
  for(row in 1:nrow(data)){
    if(dummy_data[[row, 1]] == 'closeness') {
      dummy_data[[row, 1]] <- 0
    } else if (dummy_data[[row, 1]] == 'control'){
      dummy_data[[row, 1]] <- 1
    } else if (dummy_data[[row, 1]] == 'size'){
      dummy_data[[row, 1]] <- 2
    } else if (dummy_data[[row, 1]] == 'open'){
      dummy_data[[row, 1]] <- 3
    } else if (dummy_data[[row, 1]] == 'conflict'){
      dummy_data[[row, 1]] <- 4
    }
  }
  return(dummy_data)
}

## Code the categorical variables
code_conditions <- function(data) {
  dummy_data <- data
  for(row in 1:nrow(data)){
    if(dummy_data[[row, 5]] == 'original') {
      dummy_data[[row, 5]] <- 0
    } else if (dummy_data[[row, 5]] == 'forced'){
      dummy_data[[row, 5]] <- 1
    } else if (dummy_data[[row, 5]] == 'together'){
      dummy_data[[row, 5]] <- 2
    }
  }
  return(dummy_data)
}

u_dummy <- code_metaphors(total_unpolite)
u_dummy <- code_conditions(u_dummy)

a_dummy <- code_metaphors(total_audience)
a_dummy <- code_conditions(a_dummy)

e_dummy <- code_metaphors(total_entity)
e_dummy <- code_conditions(e_dummy)

u_control <- lm(condition ~ metaphor_measure * normalized_score, data=u_dummy)
summary(u_control)

## almost certain this is correct
u_t <- lm(normalized_scores ~ metaphor_measure:condition, data=filter(total_unpolite, metaphor_measure=='conflict'))
summary(u_t)

a_t <- lm(normalized_scores ~ metaphor_measure:condition, data=a_dummy)
summary(a_t)

e_t <- lm(normalized_scores ~ metaphor_measure:condition, data=e_dummy)
summary(e_t)
```

Basically the answer is... not much. But we can try for all of the different conditions.
```{r}
generate_anovas <- function(data) {
  print('closeness, conflict, control, open, size')
  print(summary(generate_anova(data, 'closeness')))
  print(summary(generate_anova(data, 'conflict')))
  print(summary(generate_anova(data, 'control')))
  print(summary(generate_anova(data,'open')))
  print(summary(generate_anova(data,'size')))
}

generate_anovas_by_mean <- function(data) {
  print('closeness, conflict, control, open, size')
  print(summary(generate_anova_by_mean(data, 'closeness')))
  print(summary(generate_anova_by_mean(data, 'conflict')))
  print(summary(generate_anova_by_mean(data, 'control')))
  print(summary(generate_anova_by_mean(data,'open')))
  print(summary(generate_anova_by_mean(data,'size')))
}

# not particularly useful up above, but handy for having during test period. 
generate_anova <- function(data, metaphor_filter) {
  return(aov(normalized_scores ~ condition, data=filter(data, metaphor_measure==metaphor_filter)))
}

generate_anova_by_mean <- function(data, metaphor_filter) {
  # normalized SCORE not normalized scoreS
  return(aov(normalized_score ~ condition, data=filter(data, metaphor_measure==metaphor_filter)))
}
```

```{r}
print('unpolite')
generate_anovas(total_unpolite)
```

```{r}
print('audience')
generate_anovas(total_audience)
```

```{r}
print('entity')
generate_anovas(total_entity)
```


### Ordinal Models
We need to factor things often.
```{r}
factor_normalized_scores <- function(data) {
  factored <- data
  factored$normalized_scores <- factor(factored$normalized_scores)
  return(factored)
}
```

Now try doing ordinal ranked response analysis
```{r}
t <- total_unpolite
t$normalized_scores <- factor(t$normalized_scores)
t <- factor_normalized_scores(total_unpolite)

factored_unpolite <- factor_normalized_scores(total_unpolite)
ordinal_mod <- clm(condition ~ metaphor_measure * normalized_scores, data=t)
ordinal_mod_no_cond <- clm(num_ranking ~ metaphor_measure * condition - condition, data=factor_normalized_score(total_unpolite))
anova(ordinal_mod, ordinal_mod_no_cond)
summary(ordinal_mod)
```

### Bootstrapping the ~Data~
Now let's try bootstrapping this bad boy
```{r}
generate_bootstrapped_data <- function(data, n) {
  generated_data <- data[0,]
  for(i in 1:n) {
    generated_data <- rbind(generated_data, sample_n(data, 1))
  }
  return(generated_data)
}
```

Perhaps fortunately, perhaps not, this brings significance values wayyyyy up. Let's compare:
```{r}
unpolite_bootstrapped <- generate_bootstrapped_data(total_unpolite, 150)
print('unpolite')
generate_anovas(unpolite_bootstrapped)
```

```{r}
audience_bootstrapped <- generate_bootstrapped_data(total_audience, 150)
print('audience')
generate_anovas(audience_bootstrapped)
```

```{r}
entity_bootstrapped <- generate_bootstrapped_data(total_entity, 150)
print('entity')
generate_anovas(entity_bootstrapped)
```




